## ğŸ›’ Retail Data Pipeline Project

A simulated end-to-end retail data pipeline project using Python, PostgreSQL, and FakeStoreAPI. This project ingests data daily, stores it in a PostgreSQL database, and generates visual analytics in Jupyter Notebook.

---

## ğŸ“¦ Project Overview

This project simulates a small e-commerce store. The goal is to:
- Ingest fake retail data daily (products, users, carts)
- Store and manage the data using PostgreSQL
- Analyze sales trends and customer behavior
- Visualize key business insights in a Jupyter Notebook

---

## ğŸ› ï¸ Tech Stack

| Tool | Purpose |
|------|---------|
| ğŸ Python | Scripting, ingestion, analysis |
| ğŸ˜ PostgreSQL | Relational database |
| ğŸ“¦ FakeStoreAPI | Simulated retail data |
| ğŸ“Š Jupyter Notebook | Visualization and exploration |
| ğŸ§® SQL (Materialized Views) | Aggregation and analytics |
| ğŸ§° VS Code | Development environment |
| ğŸ“… Windows Task Scheduler | Automate daily ingestion |

---

## ğŸ“ Project Structure

retail-data-pipeline/
â”œâ”€â”€ data_ingest/ # Python scripts for data ingestion
â”‚ â”œâ”€â”€ fetch_initial_data.py
â”‚ â””â”€â”€ fetch_daily_data.py
â”œâ”€â”€ notebooks/ # Jupyter notebook analysis
â”‚ â””â”€â”€ retail_analysis.ipynb
â”œâ”€â”€ sql/ # SQL scripts for views
â”‚ â”œâ”€â”€ create_tables.sql
â”‚ â”œâ”€â”€ materialized_views.sql
â”œâ”€â”€ logs/ # (Optional) Ingestion logs
â”œâ”€â”€ analytics/ # (Optional) Final reports
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸš€ Step-by-Step Guide

---

### ğŸ§© Phase 1: Initial Setup


### âœ… Install Python, PostgreSQL, and VS Code  
### âœ… Create and activate a virtual environment


python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

### âœ… Connect VS Code to GitHub repo
### âœ… Create database in PostgreSQL: retail_data_pipeline


### ğŸ”„ Phase 2: Data Ingestion


### ğŸ“¦ Initial Load Script:

python data_ingest/fetch_initial_data.py

### ğŸ“… Daily Fetch Script:

python data_ingest/fetch_daily_data.py

### ğŸ“ Optionally run via .bat file and Windows Task Scheduler.


### ğŸ—ƒï¸ Phase 3: Database Structure

### ğŸ§± Create tables:

products

users

carts

cart_items

### ğŸ§  Add Materialized Views:

top_products_mv

daily_revenue_mv

top_users_mv

Refresh them when data changes:

REFRESH MATERIALIZED VIEW top_products_mv;
REFRESH MATERIALIZED VIEW daily_revenue_mv;
REFRESH MATERIALIZED VIEW top_users_mv;


### ğŸ“Š Phase 4: Data Analysis


### ğŸ“ In notebooks/retail_analysis.ipynb, visualize:

### ğŸ† Top-Selling Products

### ğŸ“ˆ Daily Revenue Trends

### ğŸ™‹â€â™‚ï¸ Most Loyal Users

### ğŸ“ Example: Top products chart

sns.barplot(data=df_top_products, y="title", x="total_sold")
All queries pull data from materialized views to ensure performance.

### ğŸ“… Automation

Set fetch_daily_data.py to run every day at 14:00 via Windows Task Scheduler or cron.


### ğŸ¤ Contributing

This is a personal learning project â€” but PRs and suggestions are welcome!

### ğŸ“„ License

MIT License

### ğŸ™Œ Credits

FakeStoreAPI for fake retail data

PostgreSQL for DB magic

Matplotlib & Seaborn for visual storytelling
